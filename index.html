<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
	Used for SIAM 2022
-->
<html>
<head>
    <title>SIAM 2024 workshop</title>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"/>
    <link rel="stylesheet" href="assets/css/main.css"/>
    <noscript>
        <link rel="stylesheet" href="assets/css/noscript.css"/>
    </noscript>
</head>
<body class="is-preload">

<!-- Wrapper -->
<div id="wrapper">

    <!-- Header -->
    <header id="header" class="alt">
        <!--        <span class="logo"><img width="120px" src="images/siam-logo.svg" alt=""/></span>-->
        <h1>2nd International Workshop on <br/> <strong>Socially Interactive Autonomous Mobility (SIAM)</strong></h1>
        <p>35th IEEE Intelligent Vehicles Symposium (IV24)</br>Jeju Shinhwa World, Jeju Island, Korea<br/> June 2nd,
            2024 <br/>
            <!--            Recording: <a href="https://www.youtube.com/@SIAMWorkshop">SIAM-->
            <!--                YouTube channel</a>-->
        </p>
        <!--        <strong> Time: half day on Sunday June 04, 2023. </br> Location: TBD.</strong>-->
    </header>

    <!-- Nav -->
    <nav id="nav">
        <ul>
            <li><a href="#intro" class="active">About</a></li>
            <li><a href="#Call for papers" class="active">Call for papers</a></li>
            <li><a href="#program" class="active">Program</a></li>
            <li><a href="#Invited_Speaker" class="active">Speakers</a></li>
            <li><a href="#Committee" class="active">Committee</a></li>
            <li><a href="#organizers" class="active">Organizers</a></li>
            <li>
                <div class="dropdown">
                    <button class="dropbtn">Previous</button>
                    <div class="dropdown-content">
                        <a href="https://interactive-driving.github.io/SIAM-IV23/">1st SIAM (IV23')</a>
                    </div>
                </div>
            </li>
        </ul>
    </nav>

    <!-- Main -->
    <div id="main">

        <!-- Introduction -->
        <section id="intro" class="main">
            <div class="spotlight">
                <div class="content">
                    <header class="major">
                        <h2>About</h2>
                    </header>
                    <p>One of the main goals of our workshop is to bridge the gap between Computational Cognitive &
                        Behavior Science, Explainable AI, Transportation, and the Autonomous Driving community.
                        Our SIAM workshop mainly targets theoretical frameworks and practical algorithms of perception,
                        decision-making, and planning integrated with social factors and computational cognitive science
                        to enable autonomous vehicles (AVs) to interact with human agents in a socially compatible way.
                        Specifically, the topics are as follows, but not limited to:
                    <ul>
                        <li>Applications of AVs interacting with human agents;</li>
                        <li>Algorithms of perception, decision-making, planning for human-like AVs;</li>
                        <li>Cognitive aspects and models for autonomous driving;</li>
                        <li>Cognitive and mental modeling toward socially driving, e.g., Theory of Mind and Theory of
                            Machine;
                        </li>
                        <li>Social cues for AVs in interactive driving tasks;</li>
                        <li>Action-reaction cycle modeling and validation;</li>
                        <li>Explainable interaction and planning in interactive driving tasks;</li>
                        <li>Evaluation and quantification of inter-human interactions and their implementations to
                            human-AV interactions;
                        </li>
                        <li>Human driving behavior/intention modeling, simulation, and analysis;</li>
                        <li>Heterogeneous human-agent teams;</li>
                        <li>Interactive traffic scenes analysis;</li>
                        <li>Interaction pattern learning, extraction, and recognition;</li>
                        <li>Interactive simulations and humans-in-the-loop simulations;</li>
                        <li>Learning-based theory for social interaction among human drivers;</li>
                        <li>Social and group intelligence in multiple human agent interaction;</li>
                        <li>Spatiotemporal driving behaviors in interactive traffic scenes;</li>
                    </ul>

                    </p>
                    <ul class="actions">
                        <li><a href="learn_more.html" class="button">Learn More</a></li>
                    </ul>
                </div>
                <!--                <span class="image"><img src="images/....png" alt=""/></span>-->
            </div>
        </section>

        <section id="Call for papers" class="main style1">
            <div class="container">
                <header class="major">
                    <h2>Call for papers</h2>
                </header>

                If you are interested in contributing, please take the following steps:
                <li><strong>Select our Workshop:</strong> The 2nd International Workshop on Socially Interactive
                    Autonomous Mobility (SIAM)
                </li>
                <li><strong>Submit Using the Workshop Code:</strong> SociallyInteractive</li>
                The remainder of the submission process will be identical to that of regular conference submissions. See
                more details at <a href="https://ieee-iv.org/2024/call-for-workshop-papers/">https://ieee-iv.org/2024/call-for-workshop-papers/</a>.
                <br></br>

                <p><strong> Workshop Paper Review:</strong> Papers submitted for the workshop will undergo the same
                    review process as the
                    conference papers and will be published in the same proceedings.</p>

                <!--                <p><strong> Join via Zoom!</strong>-->
                <!--                    During the upcoming IEEE IV 2024 conference, workshops will provide Zoom meetings as an option. Even-->
                <!--                    those who didn’t register for the conference will have the opportunity to join the Zoom meetings for-->
                <!--                    the workshops. Some of the presenters and organizers of certain workshop sessions will also-->
                <!--                    participate via Zoom. For this year’s conference, only the invited speakers who won’t be-->
                <!--                    participating in the entire event will be able to join the presentations through Zoom. However,-->
                <!--                    presenters who have submitted papers are required to attend the conference in person. Our workshop-->
                <!--                    will be recorded and uploaded to the-->
                <!--                    <a href="https://www.youtube.com/@SIAMWorkshop">SIAM YouTube channel</a>.</p>
                -->
                <!--                <p>Authors are invited to submit full-length papers up to 6 pages for technical content including-->
                <!--                    figures and references. Additional pages will be charged at the rate of $100 per page and is limited-->
                <!--                    to two pages per paper. Each paper will undergo a peer-reviewing process by at least two-->
                <!--                    independent reviewers. Contributions will be reviewed according to relevance, originality and novel-->
                <!--                    ideas, technical soundness and quality of presentation. Each accepted paper must be covered by at-->
                <!--                    least one non-studentregistration. Additional papers by the same authors will be charged at the flat-->
                <!--                    rate of $400 per paper.-->

                <!--                    To maximize visibility and impact, all accepted papers will be published in IEEE Xplore digital-->
                <!--                    library through Open Preview and will be freely accessible and downloadable by all, in final format,-->
                <!--                    beginning one month prior to the conference and through the conference end date.</p>-->

                <!--                <ul>-->
                <!--                    <strong>Submission:</strong>-->
                <!--                    <li> The submission portal is now open and authors can submit workshop papers.-->
                <!--                        This year we will not have workshop codes, rather authors follow the submission link (<a-->
                <!--                                href="https://edas.info/newPaper.php?c=30459&track=115618">-->
                <!--                            https://edas.info/newPaper.php?c=30459&track=115618 </a>) and select the-->
                <!--                        corresponding workshop from the list.-->
                <!--                    </li>-->

                <!--                    <li> Furthermore, here is the link with for the paper submission instructions with necessary-->
                <!--                        screenshots:-->
                <!--                        <a href="https://2023.ieee-iv.org/paper-submission/">-->
                <!--                            https://2023.ieee-iv.org/paper-submission/ </a>.-->
                <!--                    </li>-->
                <!--                </ul>-->

                <!--                <ul>-->
                <!--                    <strong>Finance:</strong>-->
                <!--                    <li>-->
                <!--                        Registration for attending the workshop-day only will be for a separate fee, <strong>except for-->
                <!--                        IEEE ITSS members</strong>, they will receive free attendance to the workshop-day.-->
                <!--                    </li>-->
                <!--                    <li>-->
                <!--                        In case of accepted workshop paper, one author has to pay the full publication fee to include-->
                <!--                        the-->
                <!--                        paper into the proceedings.-->
                <!--                    </li>-->
                <!--                </ul>-->

                <ul><strong>Important Deadlines:</strong>
                    <li><strong>
                        <del>February 01, 2024</del>
                        <b style='color:red;'>February 05, 2024</b> (firm deadline, no extension):</strong> Workshop
                        Paper Submission Deadline
                    </li>
                    <li><strong>March 30, 2024:</strong> Workshop Paper Notification of
                        Acceptance
                    </li>
                    <li><strong>April 22, 2024:</strong> Workshop Final Paper Submission Deadline
                    </li>
                </ul>

                <ul class="actions">
                    <li><a href="./files/CFP-IV24-SIAM_Workshop.pdf" class="button">Download CFP</a></li>
                </ul>

            </div>
        </section>


        <section id="program" class="main style1">
            <div class="container">
                <header class="major">
                    <h2>Program (13:00-16:30, June 2nd, 2024)</h2>
                </header>

                <!--                <p>The program of this workshop includes 7 talks in several sessions. </br>-->
                <!--                    - The talks will be streaming online via: <a href="https://mcgill.zoom.us/j/81817355928">zoom-->
                <!--                        meeting</a>.</br>-->
                <!--                    - Recordings of all talks will be available on the <a href="https://www.youtube.com/@SIAMWorkshop">SIAM-->
                <!--                        YouTube channel</a>.</br>-->
                <!--                    - 👉 Check out our <a href="./files/SIAM_Workshop_IV23_Flyer.pdf">Flyer</a>!-->
                <!--                </p>-->

                <div class="table-wrapper">
                    <table>
                        <thead>
                        <tr>
                            <th>Time</th>
                            <th>Speaker</th>
                            <th>Topic (click to see more details)</th>
                        </tr>
                        </thead>
                        <tbody>

                        <tr>
                            <td>13:00-13:10</td>
                            <td>Organizer</td>
                            <td>Openning</td>
                        </tr>

                        <tr>
                            <td>13:10-14:10</td>
                            <td>Presenters</td>
                            <td>A 5-min poster presentation for each paper.</td>
                        </tr>

                        <tr>
                            <td>14:10-15:10</td>
                            <td>Presenters</td>
                            <td>Interactive Poster Presentations.</td>
                        </tr>

                        <tr onClick='toggleRow(this)'>
                            <td>15:10-15:40</td>
                            <td><strong><a href="https://environment.leeds.ac.uk/transport/staff/950/dr-yee-mun-lee">Yee
                                Mun Lee</a></strong></br> University of Leeds
                            </td>
                            <td> An overview of Pedestrian-Automated Vehicle interaction studies at the University of
                                Leeds
                            </td>
                            <td class='expanded-row-content hide-row'>Abstract: In the future, Automated Vehicles (AVs)
                                will need to interact with other road users, such as cyclists, pedestrians, and other
                                vehicles. To enhance safety, improve traffic flow, and increase user acceptance and
                                trust in AVs, pedestrians and other road users need to understand the AVs' intentions,
                                communication, and behaviour. We have conducted over ten experimental studies
                                understanding P-AV interaction in our pedestrian lab at the University of Leeds. This
                                presentation will provide an overview of what we have learnt, the key findings and our
                                future directions.
                            </td>
                        </tr>

                        <tr onClick='toggleRow(this)'>
                            <td>15:50-16:20</td>
                            <td><strong><a href="https://www.tudelft.nl/staff/a.zgonnikov/">Arkady
                                Zgonnikov</a></strong></br> TU Delft
                            </td>
                            <td> In the driver's mind: cognitive modeling of human drivers in interactions with
                                automated vehicles
                            </td>
                            <td class='expanded-row-content hide-row'>Abstract: Human behavior models are critical for
                                the development of automated vehicles (AVs): they are used for behavior prediction,
                                interaction planning, virtual training and testing, and benchmarking of AVs. However,
                                diverse models used for each of these applications often face similar challenges when it
                                comes to accuracy, generalization, interpretability, and scalability. In this talk, I
                                will argue that improving the ability of AVs to interact with humans requires
                                fundamental scientific research into human cognitive processes during traffic
                                interactions. In my lab we are developing a new generation of human driver behavior
                                models to address this challenge. I will present an overview of our recent work covering
                                several complementary approaches for modeling human drivers’ decision making and
                                operational behavior in traffic interactions, and will illustrate the potential of these
                                models for AV development.
                            </td>
                        </tr>


                        <tr>
                            <td>16:20-16:30</td>
                            <td>Organizer</td>
                            <td>Discussion and conclusions</td>
                        </tr>

                        </tbody>
                    </table>
                </div>
            </div>
            Accepted paper list:
            <ol type="1">
                <li>Tianyi Li, Shian Wang, Mingfeng Shang, Raphael Stern*. Can Cyberattacks on Adaptive Cruise Control
                    Vehicles Be Effectively Detected?
                </li>
                <li> Mingfeng Shang, Shian Wang, Tianyi Li, Raphael Stern*. Interaction-Aware Model Predictive Control
                    for Autonomous Vehicles in Mixed-Autonomy Traffic.
                </li>
                <li> Wissam Kontar, Yongju Kim, Xinzhi Zhong, Soyoung Ahn*. On the Need for Personalization in the
                    Design
                    of Autonomous Vehicle Driver Models.
                </li>
                <li> Frederik Werner*, René Oberhuber, Johannes Betz. Accelerating Autonomy: Insights from Pro Racers in
                    the Era of Autonomous Racing - an Expert Interview Study.
                </li>
                <li> Kaifeng Wang*, Qi Liu, Xueyuan Li, Fan Yang. AF-DQN: A Large-Scale Decision-Making Method at
                    Unsignalized Intersections with Safe Action Filter and Efficient Exploratory Training Strategy.
                </li>
                <li> Juhui Gim, Changsun Ahn*. Integrating Intrinsic Reasoning and Negotiation Mechanisms in
                    Driver-Driver Social Interactions.
                </li>
                <li> Chaopeng Zhang*, Wenshuo Wang, Zhaokun chen, Junqiang Xi. 100 Drivers, 2200 Km: A Natural Dataset
                    of
                    Driving Style Toward Human-Centered Intelligent Driving Systems.
                </li>
                <li> Efimia Panagiotaki*, Tyler Reinmund, Brian Liu, Stephan Mouton, Luke Pitt, Arundathi Shaji
                    Shanthini, Matthew Towlson, Wayne Tubby, Chris Prahacs, Daniele De Martini, Lars Kunze. RobotCycle:
                    Assessing Cycling Safety in Urban Environments.
                </li>
                <li> Golam Md Muktadir, Taorui Huang*, Srishti Sripada, Rishi Saravanan, Amelia Yuan, Jim. Whitehead
                    PedAnalyze - Pedestrian Behavior Annotator and Ontology.
                </li>
                <!--                <li> <del>Vladimir Maksimenko, Xinwei Li, Eui-Jin Kim, Yi-Shin Lin, Prateek Bansal*. Advantage of Video-Based-->
                <!--                    Moral Machine Experiments: Evidence from Brain Data in the Moral Dilemmas Faced by Autonomous-->
                <!--                    Vehicle.</del>-->
                <!--                </li>-->
                <li> Yuhao Luo, Kehua Chen, Meixin Zhu*. GRANP: A Graph Recurrent Attentive Neural Process Model for
                    Vehicle Trajectory Prediction.
                </li>
                <li> Qi Liu*, Yujie Tang, Xueyuan Li, Fan Yang, Xin Gao, Zirui Li. SIF-STGDAN: A Social Interaction
                    Force
                    Spatial-Temporal Graph Dynamic Attention Network for Decision-Making of Connected and Autonomous
                    Vehicles.
                </li>
            </ol>

        </section>

        <section id="Invited_Speaker" class="main style1">
            <div class="container">
                <header class="major">
                    <h2>Invited Speakers</h2>
                </header>
                <div class="main-topic">
                    <div class="left-text">
                        <h3><strong><a href="https://environment.leeds.ac.uk/transport/staff/950/dr-yee-mun-lee">Yee
                            Mun Lee</a></strong></br>University of Leeds</h3>
                        <p>
                            Yee Mun Lee is currently a senior research fellow at the Institute for Transport Studies,
                            University of Leeds. She obtained her BSc (Hons) in Psychology and her PhD degree in driving
                            cognition from The University of Nottingham Malaysia in 2012 and 2016 respectively. Her
                            current research interests include investigating the interaction between automated vehicles
                            and other road users, by using various methods, especially virtual reality experimental
                            designs. Yee Mun was the leader of the 'Methodologies, Evaluation and Impact Assessment'
                            Work Package of the EU-funded project, <a href="https://www.interact-roadautomation.eu">interACT</a>,
                            and was
                            involved in <a href="https://www.l3pilot.eu">L3Pilot</a>, where she investigated the Users'
                            Evaluation and
                            Experience of a Level 3 system. She is now a Co-lead of the User Sub-project of another
                            EU-funded project, <a href="https://www.hi-drive.eu">Hi-Drive</a>. Finally, Yee Mun is one
                            of the
                            SHAPE-IT project supervisors, where she continues her research on Human interaction with AVs
                            in Urban Scenarios (<a href="https://www.shape-it.eu">www.shape-it.eu</a>), and also
                            actively
                            involved in the International
                            Organisation for Standardisation (ISO).
                        </p>
                    </div>

                    <div class="right-picture">
                        <img src="images/Speakers/Yee_Mun_Lee.jpg">
                    </div>
                </div>

                <div class="main-topic">
                    <div class="left-text">
                        <h3><strong><a href="https://www.tudelft.nl/staff/a.zgonnikov/">Arkady
                            Zgonnikov</a></strong></br>TU Delft</h3>
                        <p>
                            Arkady Zgonnikov is an interdisciplinary cognitive scientist specializing in cognitive
                            modeling of human behavior in human-robot interactions, with a particular focus on automated
                            driving. He earned his MSc in Applied Mathematics from Saint Petersburg State University in
                            2009 and his PhD in Computer Science and Engineering from The University of Aizu in 2014.
                            His early research concentrated on the mathematical modeling of intermittent motor control
                            in human operators. In 2015, Arkady joined the Department of Psychology at the University of
                            Galway as an Irish Research Council Postdoctoral Fellow, where he studied the response
                            dynamics of decision making. In 2017, he returned to The University of Aizu to explore the
                            interplay between decision making and motor behavior. In 2019, he joined the Department of
                            Cognitive Robotics at Delft University of Technology as a postdoctoral researcher and was
                            promoted to assistant professor in 2020. Arkady's current research aims to understand human
                            cognition in traffic interactions through both mathematical and data-driven modeling. He is
                            deeply concerned with the ethical and societal impacts of robotics and AI technology,
                            striving to develop concrete methods that empower humans to meaningfully control artificial
                            intelligent systems.
                        </p>
                    </div>

                    <div class="right-picture">
                        <img src="images/Speakers/Zgonnikov_Arkady.jpg">
                    </div>
                </div>


            </div>
        </section>

        <section id="Committee" class="main style1">
            <div class="container">
                <header class="major">
                    <h2>Program Committee</h2>
                    <div class="row">
                        <div class="column">
                            <!--                            <a href="https://www.trailab.utias.utoronto.ca/current-members"><strong>Steven-->
                            <!--                            Waslander</strong>, University of Toronto</a></br>-->
                            <a href="https://jiachengzhuml.github.io/"><strong>Jiacheng
                                Zhu</strong>, Massachusetts Institute of Technology</a></br>
                            <a href="https://mczhi.github.io/"><strong>Zhiyu Huang</strong>, Nanyang Technological
                                University</a></br>
                            <a href="https://chengzhanhong.github.io/"><strong>Zhanhong Cheng</strong>, McGill
                                University</a></br>
                            <a href="https://www.linkedin.com/in/yilin-wang-65377b185/"><strong>Yilin Wang</strong>,
                                Purdue University</a></br>
                            <a href="https://zhuangdingyi.github.io/"><strong>Dingyi Zhuang</strong>,
                                Massachusetts Institute of Technology</a></br>
                            <!--                            <a href="https://www.coe.pku.edu.cn/teaching/all_time/10394.html"><strong>Chang-->
                            <!--                                Liu</strong>, Peking University</a></br>-->
                            <!--                            <a href="https://ziranw.github.io/"><strong>Ziran Wang</strong>, Purdue University</a></br>-->
                            <!--                            <a href="https://www.fshuo.tech/"><strong>Shuo Feng</strong>, University of-->
                            <!--
                                                   Michigan</a></br>-->
                        </div>


                        <div class="column"><a href="tbd">
                            <a href="https://ruichen.pub/"><strong>Rui Chen</strong>, Carnegie Mellon
                                University</a></br>
                            <a href="https://khchen-hp.github.io/"><strong>Kehua Chen</strong>, Hong Kong University of
                                Science and Technology</a></br>
                            <a href="https://yeping-hu.github.io/"><strong>Yeping Hu</strong>, Lawrence Livermore
                                National Laboratory</a></br>
                            <a href="https://choi-seongjin.github.io/"><strong>Seongjin Choi</strong>, University of
                                Minnesota</a></br>
                            <a href="https://tianyili.xyz/"><strong>Tianyi Li</strong>, University of
                                Minnesota</a></br>
                            <!--                            <strong>Vaibhav Unhelkar</strong>,-->
                            <!--                            Rice-->
                            <!--                            University</a></br>-->
                            <!--                            <a href="https://pure.qub.ac.uk/en/persons/chongfeng-wei"><strong>Chongfeng Wei</strong>,-->
                            <!--                                Queen's University Belfast</a></br>-->
                            <!--                            <a href="https://idsc.ethz.ch/research-frazzoli/people/person-detail.MjIxNjc1.TGlzdC8yNjg5LDQ4ODg4MTE2Mw==.html"><strong>Alessandro-->
                            <!--                                Zanardi</strong>, ETH Zürich</a></br>-->
                            <!--                            <a href="https://gioele.science/"><strong>Gioele Zardini</strong>, ETH Zürich</a></br>-->
                            <!--                            <a href="https://xushengluo92.github.io/"><strong>Xusheng Luo</strong>, Carnegie Mellon-->
                            <!--                                University</a></br>-->
                        </div>
                    </div>
                </header>
            </div>
        </section>


        <section id="organizers" class="main style1">
            <div class="container">

                <header class="major">
                    <h2>Organizers</h2>
                </header>


                <div class="box alt">
                    <div class="row gtr-round">

                        <div class="col-2">
                            <img class="circular-square" src="images/Organizers/Chengyuan_Zhang.jpg"/>
                            <h5><a href="https://chengyuan-zhang.github.io/"><strong>Chengyuan Zhang</strong></br>
                                McGill University</a></h5>
                        </div>

                        <div class="col-2">
                            <img class="circular-square" src="images/Organizers/Letian_Wang.jpg"/>
                            <h5><a href="https://letianwang0.wixsite.com/myhome"><strong>Letian Wang</strong></br>
                                University of Toronto</a></h5>
                        </div>

                        <div class="col-2">
                            <img class="circular-square" src="images/Organizers/yueyang.jpg"/>
                            <h5><a href="https://environment.leeds.ac.uk/transport/pgr/10946/yueyang-wang"><strong>Yueyang
                                Wang</strong></br>
                                University of Leeds</a></h5>
                        </div>

                        <div class="col-2">
                            <img class="circular-square" src="images/Organizers/Chaopeng_Zhang.jpg"/>
                            <h5><a href="https://chaopengzhang.github.io/"><strong>Chaopeng Zhang</strong></br>
                                Beijing Institute of Technology</a></h5>
                        </div>

                        <div class="col-2">
                            <img class="circular-square" src="images/Organizers/Yuxiao.png"
                                 alt=""/>
                            <h5><a href="https://research.nvidia.com/person/yuxiao-chen"><strong>Dr. Yuxiao
                                Chen</strong></br> NVIDIA</a></h5>
                        </div>

                        <div class="col-2">
                            <img class="circular-square" src="images/Organizers/Jiachen_li.jpg"
                                 alt=""/>
                            <h5><a href="https://jiachenli94.github.io"><strong>Prof. Jiachen Li</strong></br> UC
                                Riverside</a></h5>
                        </div>

                        <div class="col-2">
                            <img class="circular-square" src="images/Organizers/gustav.jpg"/>
                            <h5><a href="https://environment.leeds.ac.uk/transport/staff/957/professor-gustav-markkula"><strong>Prof.
                                Gustav Markkula</strong></br>
                                University of Leeds</a></h5>
                        </div>

                        <div class="col-2">
                            <img class="circular-square" src="images/Organizers/Changliu_Liu.jpg"/>
                            <h5><a href="http://www.cs.cmu.edu/~cliu6/index.html"><strong>Prof. Changliu
                                Liu</strong></br>
                                Carnegie Mellon University</a></h5>
                        </div>

                        <div class="col-2">
                            <img class="circular-square" src="images/Organizers/Lijun_Sun.jpg"/>
                            <h5><a href="https://lijunsun.github.io/"><strong>Prof. Lijun Sun</strong></br>
                                McGill University</a></h5>
                        </div>

                        <div class="col-2">
                            <img class="circular-square" src="images/Organizers/Wenshuo_Wang.jpg"
                                 alt=""/>
                            <h5><a href="https://wenshuowang.github.io/"><strong>Prof. Wenshuo Wang</strong></br>
                                Beijing Institute of Technology</a></h5>
                        </div>

                    </div>
                </div>
                </br>
        </section>

        <section id="support" class="main style1">
            <header class="major">
                <h2>Supported by</h2>
            </header>
            <div class="container">
                <div class="row gtr-uniform">
                    <div class="col-2"><span class="image fit"><img
                            src="images/Affiliations/McGill.png"
                            alt=""/></span>
                    </div>
                    <div class="col-2"><span class="image fit"><img
                            src="images/Affiliations/university-of-toronto.png"
                            alt=""/></span>
                    </div>
                    <div class="col-2"><span class="image fit"><img
                            src="https://comms.leeds.ac.uk/wp-content/uploads/sites/51/2021/04/Visual-identity-section-images--e1618925864440.png"
                            alt=""/></span>
                    </div>
                    <div class="col-2"><span class="image fit"><img
                            src="images/Affiliations/nvidia.svg"
                            alt=""/></span>
                    </div>
                    <div class="col-2"><span class="image fit"><img
                            src="images/Affiliations/UC_Riverside_logo.png"
                            alt=""/></span>
                    </div>
                    <div class="col-2"><span class="image fit"><img
                            src="images/Affiliations/cmu.png"
                            alt=""/></span>
                    </div>
                    <div class="col-2"><span class="image fit"><img
                            src="images/Affiliations/BIT-Beijing-Institute-of-Technology-Logo-Header.png"
                            alt=""/></span>
                    </div>
                    <div class="col-2"><span class="image fit"><img
                            src="images/Affiliations/IEEE-ITSS-logo.png"
                            alt=""/></span>
                    </div>
                </div>
            </div>
    </div>
    </section>


</div>

<!-- Footer -->
<footer id="footer">
    <!--        <section>-->
    <!--            <h2>Get in touch</h2>-->
    <!--            <p>Please feel free to send us an <a href="mailto:wwsbit@gmail.com"-->
    <!--                                                 target="_top">e-mail</a> , if you have any questions regarding this-->
    <!--                workshop.</p>-->
    <!--        </section>-->

    <!--        <section>-->
    <!--            <h2>Etiam feugiat</h2>-->
    <!--            <dl class="alt">-->
    <!--                <dt>Address</dt>-->
    <!--                <dd>1234 Somewhere Road &bull; Nashville, TN 00000 &bull; USA</dd>-->
    <!--                <dt>Phone</dt>-->
    <!--                <dd>(000) 000-0000 x 0000</dd>-->
    <!--                <dt>Email</dt>-->
    <!--                <dd><a href="#">information@untitled.tld</a></dd>-->
    <!--            </dl>-->
    <!--            <ul class="icons">-->
    <!--                <li><a href="#" class="icon brands fa-twitter alt"><span class="label">Twitter</span></a></li>-->
    <!--                <li><a href="#" class="icon brands fa-facebook-f alt"><span class="label">Facebook</span></a></li>-->
    <!--                <li><a href="#" class="icon brands fa-instagram alt"><span class="label">Instagram</span></a></li>-->
    <!--                <li><a href="#" class="icon brands fa-github alt"><span class="label">GitHub</span></a></li>-->
    <!--                <li><a href="#" class="icon brands fa-dribbble alt"><span class="label">Dribbble</span></a></li>-->
    <!--            </ul>-->
    <!--        </section>-->

    <span class="copyright"><img width="20%" src="images/SIAM-logo.svg"/></span>
    <p class="copyright">&copy; Chengyuan Zhang. All rights reserved. Design: <a
            href="https://html5up.net">HTML5 UP</a>.<br>
        <span id="busuanzi_container_site_uv">
      <span id="busuanzi_value_site_uv"></span> <span>vistors</span>
    </span>&<span id="busuanzi_container_site_pv">
      <span id="busuanzi_value_site_pv"></span> <span>views since December 2022.</span>
        </span></p>

</footer>

</div>

<!-- Scripts -->
<script src="assets/js/jquery.min.js"></script>
<script src="assets/js/jquery.scrollex.min.js"></script>
<script src="assets/js/jquery.scrolly.min.js"></script>
<script src="assets/js/browser.min.js"></script>
<script src="assets/js/breakpoints.min.js"></script>
<script src="assets/js/util.js"></script>
<script src="assets/js/main.js"></script>

<script>
    const toggleRow = (element) => {
        element.getElementsByClassName('expanded-row-content')[0].classList.toggle('hide-row');
        console.log(event);
    }
</script>
<script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

</body>
</html>
